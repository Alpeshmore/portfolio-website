import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam
import numpy as np
import cv2
from sklearn.model_selection import train_test_split

# Step 1: Load the MNIST dataset
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()

# Step 2: Preprocess the data
# Normalize the data to range [0, 1]
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

# Reshape data for the neural network
X_train = X_train.reshape(-1, 28, 28, 1)
X_test = X_test.reshape(-1, 28, 28, 1)

# One-hot encode the labels
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)

# Step 3: Define the Neural Network model
model = Sequential([
    Flatten(input_shape=(28, 28, 1)),                # Input Layer
    Dense(128, activation='relu'),                  # Hidden Layer
    Dense(10, activation='softmax')                 # Output Layer
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Step 4: Train the model
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

# Step 5: Evaluate the model
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_accuracy:.2f}")

# Step 6: Real-time testing with webcam input
def preprocess_image(image):
    """Preprocess the captured image to feed into the model."""
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # Resize to 28x28
    resized = cv2.resize(gray, (28, 28))
    # Normalize
    normalized = resized.astype('float32') / 255.0
    # Reshape for the model
    return normalized.reshape(1, 28, 28, 1)

# Initialize webcam
cap = cv2.VideoCapture(0)
print("Press 'q' to quit and 'c' to capture an image.")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Display the frame
    cv2.imshow('Webcam', frame)

    # Wait for key press
    key = cv2.waitKey(1) & 0xFF

    if key == ord('c'):  # Capture frame
        processed_image = preprocess_image(frame)
        prediction = model.predict(processed_image)
        predicted_digit = np.argmax(prediction)
        print(f"Predicted Digit: {predicted_digit}")
    elif key == ord('q'):  # Quit
        break

# Release resources
cap.release()
cv2.destroyAllWindows() make project overview with name